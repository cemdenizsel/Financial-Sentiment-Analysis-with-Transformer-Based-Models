{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece\n!git clone https://github.com/google-research/bert\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T11:50:57.188207Z","iopub.execute_input":"2021-06-04T11:50:57.188644Z","iopub.status.idle":"2021-06-04T11:51:06.411817Z","shell.execute_reply.started":"2021-06-04T11:50:57.188555Z","shell.execute_reply":"2021-06-04T11:51:06.410529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Add Bertbase (bertsrc in kaggle)","metadata":{}},{"cell_type":"code","source":"!pip uninstall tensorflow==2.4.1 --yes\n\n!pip install tensorflow==1.15.0","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:51:09.709271Z","iopub.execute_input":"2021-06-04T11:51:09.709634Z","iopub.status.idle":"2021-06-04T11:52:09.726811Z","shell.execute_reply.started":"2021-06-04T11:51:09.709596Z","shell.execute_reply":"2021-06-04T11:52:09.725669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport nltk\nimport random\nimport logging\nimport tensorflow as tf\n\nimport sentencepiece as spm\n\n# configure logging\nlog = logging.getLogger('tensorflow')\nlog.setLevel(logging.INFO)\n\n# create formatter and add it to the handlers\nformatter = logging.Formatter('%(asctime)s :  %(message)s')\nsh = logging.StreamHandler()\nsh.setLevel(logging.INFO)\nsh.setFormatter(formatter)\nlog.handlers = [sh]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:52:21.278587Z","iopub.execute_input":"2021-06-04T11:52:21.278925Z","iopub.status.idle":"2021-06-04T11:52:24.958485Z","shell.execute_reply.started":"2021-06-04T11:52:21.278894Z","shell.execute_reply":"2021-06-04T11:52:24.957701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Vocab file from Dataset","metadata":{}},{"cell_type":"code","source":"regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n\ndef normalize_text(text):\n  # lowercase text\n  text = str(text).lower()\n  # remove non-UTF\n  text = text.encode(\"utf-8\", \"ignore\").decode()\n  # remove punktuation symbols\n  text = \" \".join(regex_tokenizer.tokenize(text))\n  return text\n\ndef count_lines(filename):\n  count = 0\n  with open(filename) as fi:\n    for line in fi:\n      count += 1\n  return count","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:52:28.189874Z","iopub.execute_input":"2021-06-04T11:52:28.190349Z","iopub.status.idle":"2021-06-04T11:52:28.195536Z","shell.execute_reply.started":"2021-06-04T11:52:28.190306Z","shell.execute_reply":"2021-06-04T11:52:28.194885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Progbar\nRAW_DATA_FPATH = \"../input/51k-pretrain-dataset/51k.txt\" #@param {type: \"string\"}\nPRC_DATA_FPATH = \"proc_dataset.txt\" #@param {type: \"string\"}\n\n# apply normalization to the dataset\n# this will take a minute or two\n\ntotal_lines = count_lines(RAW_DATA_FPATH)\nbar = Progbar(total_lines)\n\nwith open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n    for l in fi:\n      fo.write(normalize_text(l)+\"\\n\")\n      bar.add(1)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:52:33.608972Z","iopub.execute_input":"2021-06-04T11:52:33.609339Z","iopub.status.idle":"2021-06-04T11:52:34.642907Z","shell.execute_reply.started":"2021-06-04T11:52:33.60931Z","shell.execute_reply":"2021-06-04T11:52:34.642145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\nVOC_SIZE = 1987 #@param {type:\"integer\"}\nSUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\nNUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n\nSPM_COMMAND = ('--input={} --model_prefix={} '\n               '--vocab_size={} --input_sentence_size={} '\n               '--shuffle_input_sentence=true ' \n               '--bos_id=-1 --eos_id=-1').format(\n               PRC_DATA_FPATH, MODEL_PREFIX, \n               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n\nspm.SentencePieceTrainer.Train(SPM_COMMAND)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:52:38.645808Z","iopub.execute_input":"2021-06-04T11:52:38.64623Z","iopub.status.idle":"2021-06-04T11:52:45.25575Z","shell.execute_reply.started":"2021-06-04T11:52:38.646198Z","shell.execute_reply":"2021-06-04T11:52:45.254555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_sentencepiece_vocab(filepath):\n  voc = []\n  with open(filepath, encoding='utf-8') as fi:\n    for line in fi:\n      voc.append(line.split(\"\\t\")[0])\n  # skip the first <unk> token\n  voc = voc[1:]\n  return voc\n\nsnt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\nprint(\"Learnt vocab size: {}\".format(len(snt_vocab)))\nprint(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:17.851858Z","iopub.execute_input":"2021-06-04T11:53:17.85226Z","iopub.status.idle":"2021-06-04T11:53:17.861689Z","shell.execute_reply.started":"2021-06-04T11:53:17.852224Z","shell.execute_reply":"2021-06-04T11:53:17.860734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_sentencepiece_token(token):\n    if token.startswith(\"‚ñÅ\"):\n        return token[1:]\n    else:\n        return \"##\" + token","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:20.577524Z","iopub.execute_input":"2021-06-04T11:53:20.577912Z","iopub.status.idle":"2021-06-04T11:53:20.582072Z","shell.execute_reply.started":"2021-06-04T11:53:20.577877Z","shell.execute_reply":"2021-06-04T11:53:20.581307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:22.895065Z","iopub.execute_input":"2021-06-04T11:53:22.895641Z","iopub.status.idle":"2021-06-04T11:53:22.899716Z","shell.execute_reply.started":"2021-06-04T11:53:22.895609Z","shell.execute_reply":"2021-06-04T11:53:22.898968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\nbert_vocab = ctrl_symbols + bert_vocab","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:25.3336Z","iopub.execute_input":"2021-06-04T11:53:25.334078Z","iopub.status.idle":"2021-06-04T11:53:25.337826Z","shell.execute_reply.started":"2021-06-04T11:53:25.334047Z","shell.execute_reply":"2021-06-04T11:53:25.337176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\nprint(len(bert_vocab))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:26.776903Z","iopub.execute_input":"2021-06-04T11:53:26.777458Z","iopub.status.idle":"2021-06-04T11:53:26.782872Z","shell.execute_reply.started":"2021-06-04T11:53:26.777425Z","shell.execute_reply":"2021-06-04T11:53:26.78193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n\nwith open(VOC_FNAME, \"w\") as fo:\n  for token in bert_vocab:\n    fo.write(token+\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:33.591344Z","iopub.execute_input":"2021-06-04T11:53:33.591697Z","iopub.status.idle":"2021-06-04T11:53:33.597181Z","shell.execute_reply.started":"2021-06-04T11:53:33.591667Z","shell.execute_reply":"2021-06-04T11:53:33.596257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now Start Pretraining Step with BERT scripts","metadata":{}},{"cell_type":"code","source":"! pip install -U tokenizers\nimport tokenizers\n","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:53:56.606667Z","iopub.execute_input":"2021-06-04T11:53:56.607009Z","iopub.status.idle":"2021-06-04T11:54:04.4511Z","shell.execute_reply.started":"2021-06-04T11:53:56.606979Z","shell.execute_reply":"2021-06-04T11:54:04.45019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bwpt = tokenizers.BertWordPieceTokenizer(\n    vocab=None,\n    unk_token='[UNK]',\n    sep_token='[SEP]',\n    cls_token='[CLS]',\n    clean_text=True,\n    handle_chinese_chars=True,\n    strip_accents=True,\n    lowercase=True,\n    wordpieces_prefix='##'\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:54:06.955838Z","iopub.execute_input":"2021-06-04T11:54:06.956234Z","iopub.status.idle":"2021-06-04T11:54:06.96253Z","shell.execute_reply.started":"2021-06-04T11:54:06.956199Z","shell.execute_reply":"2021-06-04T11:54:06.961378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bwpt.train(\n    files=[\"../input/51k-pretrain-dataset/51k.txt\"],\n    vocab_size=30000,\n    min_frequency=3,\n    limit_alphabet=1000,\n    special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]']\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:54:24.748978Z","iopub.execute_input":"2021-06-04T11:54:24.749382Z","iopub.status.idle":"2021-06-04T11:54:27.034156Z","shell.execute_reply.started":"2021-06-04T11:54:24.749349Z","shell.execute_reply":"2021-06-04T11:54:27.033122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bwpt.save(\"/kaggle/working/tokenized.txt\")","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:54:31.504235Z","iopub.execute_input":"2021-06-04T11:54:31.504797Z","iopub.status.idle":"2021-06-04T11:54:31.512864Z","shell.execute_reply.started":"2021-06-04T11:54:31.504764Z","shell.execute_reply":"2021-06-04T11:54:31.511923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd bert","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:54:33.723498Z","iopub.execute_input":"2021-06-04T11:54:33.723998Z","iopub.status.idle":"2021-06-04T11:54:34.448321Z","shell.execute_reply.started":"2021-06-04T11:54:33.723967Z","shell.execute_reply":"2021-06-04T11:54:34.446901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:54:42.853033Z","iopub.execute_input":"2021-06-04T11:54:42.85346Z","iopub.status.idle":"2021-06-04T11:54:43.587445Z","shell.execute_reply.started":"2021-06-04T11:54:42.853401Z","shell.execute_reply":"2021-06-04T11:54:43.586207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ./bert/create_pretraining_data.py \\\n    --input_file=../input/51k-pretrain-dataset/51k.txt \\\n    --output_file=/kaggle/working/tf_examples.tfrecord \\\n    --vocab_file=./vocab.txt\\\n    --do_lower_case=True \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --masked_lm_prob=0.15 \\\n    --random_seed=42 \\\n    --dupe_factor=5","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:55:44.459589Z","iopub.execute_input":"2021-06-04T11:55:44.459958Z","iopub.status.idle":"2021-06-04T11:58:17.654149Z","shell.execute_reply.started":"2021-06-04T11:55:44.459927Z","shell.execute_reply":"2021-06-04T11:58:17.652818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python ../input/bertsrc/run_pretraining.py \\\n    --input_file=gs://pretrain-bucket/tf_examples.tfrecord \\\n    --output_dir=gs://pretrain-bucket/51k_pretrain_model/ \\\n    --do_train=True \\\n    --do_eval=True \\\n    --bert_config_file=/kaggle/input/bert-base-uncased/config.json \\\n    --train_batch_size=32 \\\n    --max_seq_length=128 \\\n    --max_predictions_per_seq=20 \\\n    --num_train_steps=20 \\\n    --num_warmup_steps=10 \\\n    --learning_rate=2e-5 \\\n    --use_tpu=True \\\n    --tpu_name=$TPU_NAME","metadata":{"execution":{"iopub.status.busy":"2021-06-04T12:26:31.753074Z","iopub.execute_input":"2021-06-04T12:26:31.75361Z","iopub.status.idle":"2021-06-04T12:31:06.871505Z","shell.execute_reply.started":"2021-06-04T12:26:31.753563Z","shell.execute_reply":"2021-06-04T12:31:06.870458Z"},"trusted":true},"execution_count":null,"outputs":[]}]}